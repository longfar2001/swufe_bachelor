\NeedsTeXFormat{LaTeX2e}% LaTeX 2.09 can't be used (nor non-LaTeX)
[1994/12/01]% LaTeX date must December 1994 or later
\documentclass[6pt]{article}
\pagestyle{headings}
\setlength{\textwidth}{18cm}
\setlength{\topmargin}{0in}
\setlength{\headsep}{0in}

\title{Introduction to PDEs, Fall 2022}
\author{\textbf{Homework 4} solutions}
\date{}

\voffset -1.25cm \hoffset -3.5cm \textwidth 18cm \textheight 25cm
\renewcommand{\theequation}{\thesection.\arabic{equation}}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\usepackage{amsmath}
\usepackage{amsthm}
%\usepackage{esint}
  \usepackage{paralist}
  \usepackage{graphics} %% add this and next lines if pictures should be in esp format
  \usepackage{epsfig} %For pictures: screened artwork should be set up with an 85 or 100 line screen
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[labelfont=sf]{caption}
\captionsetup{width=0.85\textwidth}
\usepackage{epstopdf}%This is to transfer .eps figure to .pdf figure; please compile your paper using PDFLeTex or PDFTeXify.
 \usepackage[colorlinks=true]{hyperref}
 \usepackage{multirow}
\input{amssym.tex}
\def\N{{\Bbb N}}
\def\Z{{\Bbb Z}}
\def\Q{{\Bbb Q}}
\def\R{{\Bbb R}}
\def\C{{\Bbb C}}
\def\SS{{\Bbb S}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}
%\newtheorem*{main}{Main Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{conjecture}{Conjecture}
\newtheorem{solution}{Solution}
%\newtheorem{proof}{Proof}
 \numberwithin{equation}{section}
%\newtheorem*{problem}{Problem}
%\theoremstyle{definition}
%\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}{Remark}
%\newtheorem*{notation}{Notation}
\newcommand{\ep}{\varepsilon}
\newcommand{\eps}[1]{{#1}_{\varepsilon}}
\newcommand{\keywords}


\def\bb{\begin}
\def\bc{\begin{center}}       \def\ec{\end{center}}
\def\ba{\begin{array}}        \def\ea{\end{array}}
\def\be{\begin{equation}}     \def\ee{\end{equation}}
\def\bea{\begin{eqnarray}}    \def\eea{\end{eqnarray}}
\def\beaa{\begin{eqnarray*}}  \def\eeaa{\end{eqnarray*}}
\def\hh{\!\!\!\!}             \def\EM{\hh &   &\hh}
\def\EQ{\hh & = & \hh}        \def\EE{\hh & \equiv & \hh}
\def\LE{\hh & \le & \hh}      \def\GE{\hh & \ge & \hh}
\def\LT{\hh & < & \hh}        \def\GT{\hh & > & \hh}
\def\NE{\hh & \ne & \hh}      \def\AND#1{\hh & #1 & \hh}

\def\r{\right}
\def\lf{\left}
\def\hs{\hspace{0.5cm}}
\def\dint{\displaystyle\int}
\def\dlim{\displaystyle\lim}
\def\dsup{\displaystyle\sup}
\def\dmin{\displaystyle\min}
\def\dmax{\displaystyle\max}
\def\dinf{\displaystyle\inf}

\def\al{\alpha}               \def\bt{\beta}
\def\ep{\varepsilon}
\def\la{\lambda}              \def\vp{\varphi}
\def\da{\delta}               \def\th{\theta}
\def\vth{\vartheta}           \def\nn{\nonumber}
\def\oo{\infty}
\def\dd{\cdots}               \def\pa{\partial}
\def\q{\quad}                 \def\qq{\qquad}
\def\dx{{\dot x}}             \def\ddx{{\ddot x}}
\def\f{\frac}                 \def\fa{\forall\,}
\def\z{\left}                 \def\y{\right}
\def\w{\omega}                \def\bs{\backslash}
\def\ga{\gamma}               \def\si{\sigma}
\def\iint{\int\!\!\!\!\int}
\def\dfrac#1#2{\frac{\displaystyle {#1}}{\displaystyle {#2}}}
\def\mathbb{\Bbb}
\def\bl{\Bigl}
\def\br{\Bigr}
\def\Real{\R}
\def\Proof{\noindent{\bf Proof}\quad}
\def\qed{\hfill$\square$\smallskip}


\graphicspath{{figures/}}
\begin{document}
\maketitle

\textbf{Name}:\rule{1 in}{0.001 in} \\
\begin{enumerate}

\item  Let us revisit the example given in the lecture: Use the method of separation of variables to find the solution to the following problem in terms of infinite series
\begin{equation}
\left\{
\begin{array}{ll}
u_t=Du_{xx},& x\in (0,L), t>0\\
u(x,0)=x, &x\in(0,L), \\
u_x(x,t)=0, & x=0,L.
\end{array}
\right.
\end{equation}

(i) Without solving this problem, use physical intuition to predict/explain what is the limit of $u(x,t)$ as $t\rightarrow \infty$?  Hint: think of $u(x,t)$ as the temperature.

(ii)  Try a separable solution $U_n(x,t)=X_n(x)T_n(t)$ of the PDE and then find it by the boundary condition;

(iii)  Let $u(x,t)=\sum^\infty_{n=1}C_nX_n(x)T_n(t)$ and then find $C_n$ by fitting the initial condition;

(iv)  Choose $D=1$ and $L=\pi$.  Use a computer program to plot the sum of the first $N$--terms $u^N(x,t)$
\[u^N(x,t):=\sum^N_{n=1}C_nX_n(x)T_n(t)\]
of the series at time $t=0.1$ by taking $N=1, 2, 3, 10$ (in different colors or lines such as dash, dot, etc) respectively.  You shall observe that $u^N(x,t)$ converges as $N$ increases (well, at least at $t=0.1$).  Therefore, though it is impossible to plot $u^\infty(x,t)$, one can, given applications, employ $u^N(x,t)$ to approximate the true solution by taking $N$ large enough.

(v)  Assume that $u^{10}(x,t)$ above is a good enough approximation of the exact solution (i.e., the infinite series).  Plot the graphs of $u^{10}(x,t)$ for $t=0.1,0.5,1,2,5,10,...$. What is the limit of this curve as $t\rightarrow \infty$.  Compare this with your prediction/explanation in (i).

(vi) Plot the graphs as in (v) with $t=-1$, -2,...You will see the blow-ups of $u(x,t)$.   That being said, the heat equation is ill-posed backward in time.

\begin{solution}
(i).  As we have discussed in class, the moral of the story is that we recognize this problem as one arising from the physical scenario that a homogeneous (no heat resource), well--insulated (NBC) bar with initial temperature distribution in the form of $x$.  Then it is natural to expect that the heat will flow from the region of higher temperature to lower temperature, with the whole bar approaching a constant temperature eventually.  On the other hand, there is no creation and degradation of the thermal energy within the bar and across the boundary (endpoints), therefore the final constant temperature is expected to be the average value of the initial temperature, thanks to the conservation of the thermal energy.  The question of how the temperature converges to the average (constant) is the goal of this homework problem;

\begin{figure}[h!]%
    \centering
    \begin{subfigure}[b]{1\textwidth}
        \includegraphics[width=0.85\textwidth]{hw2figure1.eps}
        \caption{Plots of $u^N(x,0.1)$ for $N=1,2,3$ and $10$.  It provides evidence that $N=10$ is already a good approximation.}
    \end{subfigure}
    \begin{subfigure}[b]{1\textwidth}
        \includegraphics[width=0.85\textwidth]{hw2figure2.eps}
        \caption{Absolute errors of difference terms $u^{N+1}-u^N$ for several $N$.  Left column: we observe that the error is negligible when $N$ is larger than 5, hence $N=10$ is a good approximation.  Right column: we provide further evidence that the error is infinitesimal when $N\geq10$ and this sequence is Cauchy as $N\rightarrow \infty$.  Therefore $u^N$ converges to some limiting function in a certain complete function space (complete means any Cauchy sequence converges to some limit in this space), which turns out to be our exact solution.  Again, the moral of the story is that $u^{10}$ serves as a nice approximation (to our understanding), and a large $N$ requires a longer computation hence sometimes is not taken in practice.}
    \end{subfigure}
\label{figure1}
\end{figure}
(ii).  If we try the separable solution $U=X(x)T(t)$, then $X$ satisfies the corresponding EP with NBC (do it yourself) and it is explicitly given by
\begin{align*}
X_n =\cos{\frac{n\pi x}{L}}, \, n=0,1,2,\cdots,
\end{align*}
therefore we can write $u(x,t)$ through a linear combination of $X_n$ as
\begin{align*}
u(x,t)=\sum_{n=0}^{\infty}C_{n}(t)\cos{\frac{n\pi x}{L}}.
\end{align*}
I would like to note that, when you were doing the problem, the Sturm--Liouville theorem was not expected and you can work out the problem following the separation of variable routine, which leads to the same infinite series for the solution.  Substitute $u(x,t)$ into the PDE and we will find
\begin{align*}
\sum_{n=0}^{\infty}C_{n}'(t)\cos{\frac{n\pi x}{L}}=-D\sum_{n=0}^{\infty}\big(\frac{n\pi}{L}\big)^{2}C_{n}(t)\cos{\frac{n\pi x}{L}},
\end{align*}
hence we have
\[C_{n}(t)=C_{n}(0)e^{-D(\frac{n\pi}{L})^{2}t}, n=0,1,2,\cdots\]



\begin{figure}[h!]%
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=0.85\textwidth]{hw2figure3.eps}\\
  \caption{Evolution of the temperature as time increases.  We observe that the left end increases and the right end decreases; apparently, this is due to the transfer of heat from the region of high to lower temperatures; moreover, in a large time $t\geq5$, the temperature almost reaches a homogeneity, which agrees well with our intuition and physical expectation.}\label{figure2}
\end{figure}

\begin{figure}[h!]%
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=0.85\textwidth]{hw2figure4.eps}\\
  \caption{Ill-posedness of heat equation backward in time.  We observe the blow-up of $u(x,t)$ back in time, which implies that the heat equation back in time does not make sense, though mathematically its solution is still unique as stated in HW.}\label{figure3}
\end{figure}

(iii).  Moreover, from the IC $u(x,0)=x$, we have that
\[u(x,0)=\phi(x)=C_{0}(0)+\sum_{n=1}^{\infty}C_{n}(0)\cos{\frac{n\pi x}{L}},\]
For $n=1,2,...$, we multiply BHS by $\cos \frac{n\pi x}{L}$ and integrate it over $(0,L)$ by parts to obtain
\begin{align*}
C_n(0)&=\frac{2}{L}\int_{0}^{L}\phi(x)\cos{\frac{n\pi x}{L}}dx=\frac{2}{L}\int_{0}^{L}x\cos{\frac{n\pi x}{L}}dx\\
&=\frac{2}{L}\int_{0}^{L}(\frac{L}{n\pi})xd\sin{\frac{n\pi x}{L}}=\frac{2}{n\pi}\Big(x\sin{\frac{n\pi x}{L}}\Big\vert^{L}_{0}-\int_{0}^{L}\sin{\frac{n\pi x}{L}}dx\Big)\\
&=\frac{2L}{n^2\pi^2}\cos{\frac{n\pi x}{L}}\Big\vert_0^L=\frac{2L}{n^2\pi^2}\Big((-1)^n-1\Big);
\end{align*}
to find $C_0(0)$, we just simply integrate BHS over $(0,L)$ and find
\[C_0(0)=\frac{\int_{0}^Lxdx}{L}=\frac{L}{2},\]
therefore, we have
\begin{align*}
u(x,t)=\sum_{n=0}^{\infty}C_{n}(t)\cos{\frac{n\pi x}{L}}=\frac{L}{2}+\sum_{n=1}^{\infty}\frac{2L}{n^2\pi^2}\Big((-1)^n-1\Big)e^{-D(\frac{n\pi}{L})^{2}t}\cos{\frac{n\pi x}{L}}.
\end{align*}

(iv)--(vi).
When $D=1$ and $L=\pi$, the solutions above is
\[u(x,t)=\sum_{n=0}^{\infty}C_{n}(t)\cos nx=\frac{\pi}{2}+\sum_{n=1}^{\infty}\frac{2}{n^2\pi}\Big((-1)^n-1\Big)e^{-n^{2}t}\cos nx\]
with its finite/partial sum given by
\[u^N(x,t)=\sum_{n=0}^NC_{n}(t)\cos nx=\frac{\pi}{2}+\sum_{n=1}^N\frac{2}{n^2\pi}\Big((-1)^n-1\Big)e^{-n^{2}t}\cos nx.\]

We observe the aforementioned convergence to the average value as $t\rightarrow \infty$.   One important observation is that the steady state is determined by the boundary condition, but not the initial data; moreover, for the problem backward in time, we can find that the solution \textbf{blows up} in time, i.e., $u(x,t)\rightarrow \infty$ as $t\rightarrow -\infty$ (at least for a subsequence of such $t$) for each fixed $x\in(0,L)$.
\end{solution}


\item Solve the following IBVP by separation of variables and write its solution in terms of infinite series
\begin{equation}\label{L}
\left\{
\begin{array}{ll}
u_t=Du_{xx},& x\in(-L,L),t>0\\
u(x,0)=\phi(x),&x\in(-L,L),\\
u(-L,t)=u(L,t)=0, &t>0.
\end{array}
\right.
\end{equation}
\emph{Remark:  Ambitious and motivated students are encouraged to explore this problem by replacing $(-L,L)$ by $(a,b)$, though I do not require you to do so.  We shall see later in this course that by passing $L\rightarrow\infty$, we collect \eqref{L} in the whole space.}
\begin{solution}
First of all, we have that the eigen--value problem associated with this system is
\begin{equation*}
\left\{
\begin{array}{ll}
X''+\lambda X=0,& x\in(-L,L),\\
X(-L)=X(L)=0. &
\end{array}
\right.
\end{equation*}
Now we need to find the eigen--pairs to the problem above.  While you can do it by straightforward calculations, an alternative way is to do as follows:
let us denote
\[Y(x):=X(x-L),\]
then it is easy to see that the eigen--value problem now becomes
\begin{equation*}
\left\{
\begin{array}{ll}
Y''+\lambda Y=0,& x\in(0,2L),\\
Y(0)=Y(2L)=0. &
\end{array}
\right.
\end{equation*}
It is well known that the eigen--pairs are
\[\]
\[Y_n(x)=\sin \frac{n\pi x}{2L},\lambda_n=\Big(\frac{n\pi}{2L}\Big)^2,n=1,2,...\]
therefore we have that
\[X_n(x)=Y_n(x+L)=\sin \frac{n\pi (x+L)}{2L}=\sin \Big(\frac{n\pi x}{2L}+\frac{n\pi}{2}\Big),\lambda_n=\Big(\frac{n\pi}{2L}\Big)^2,n=1,2,...\]
moreover, we can also find that
\[\int_{-L}^L X^2_n(x)dx=\int_0^{2L}Y^2_n(x)dx=\int_0^{2L}\sin^2 \frac{n\pi x}{2L}dx=L,\]
while \[\int_{-L}^L X_m(x)X_n(x)dx=0,m\neq n.\]

According to the Sturm--Liouville Theory, we are able to write the solution in terms of the infinite series
\[u(x,t)=\sum_{n=1}^\infty C_n(t) \sin \frac{n\pi (x+L)}{2L}.\]
Substituting this solution into the PDE gives us
\[\sum_{n=1}^\infty C_n'(t) \sin \frac{n\pi (x+L)}{2L}=-D\sum_{n=1}^\infty C_n(t) \Big(\frac{n\pi}{2L}\Big)^2\sin \frac{n\pi (x+L)}{2L};\]
%on the other hand, we can have from straightforward calculations that
%\[\int_{-L}^L \sin^2 \frac{n\pi x}{L}dx=\frac{x}{2}-\frac{L\sin \frac{2n\pi x}{L}}{4n\pi}\Big|_{-L}^L=L,\]
%while \[\int_{-L}^L \sin \frac{m\pi (x-L)}{L} \sin \frac{n\pi (x-L)}{L}dx=0,m\neq n.\]
Multiplying BHS of the system above by $X_n(x)$ and then integrating it over $(-L,L)$, we obtain that
\[C_n'(t)=- D \Big(\frac{n\pi}{2L}\Big)^2C_n(t);\]
solving this ODE gives us
\[C_n(t)=C_n(0)e^{-D(\frac{n\pi}{2L})^2t},\]
where $C_n(0)$ can be evaluated by the initial condition as
\[C_n(0)=\frac{1}{L}\int_{-L}^L \phi(x) \sin \frac{n\pi (x+L)}{2L}dx.\]
\end{solution}




\item  The method of separation of variables can also be used to solve wave--equation or hyperbolic equation such as of the following form
\begin{equation}\label{7}
\left\{
\begin{array}{ll}
u_{tt}=Du_{xx},& x\in(0,L),t\in \mathbb R_+,\\
u(x,0)=\phi(x), u_t(x,0)=0, &x\in(0,L),\\
u(0,t)=0, u(L,t)=0, &t\in \mathbb R_+,
\end{array}
\right.
\end{equation}
where
\[\phi(x)=
\left\{
\begin{array}{ll}
\frac{2h}{L}x, &x\in[0,\frac{L}{2}],\\
\frac{2h}{L}(L-x),& x\in[\frac{L}{2},L],
\end{array}
\right.
\]
wherein the left-hand side of the PDE, second-order derivative is taken concerning time.  You can solve (\ref{7}) by taking the following steps

(i)  Try a separable solution of the form $U_n(x,t)=X_n(x)T_n(t)$;  find the ODEs of $X_n$ and $T_n$, then solve for $X_n$ by the boundary condition thus $T_n(t)$.  Now $T_n(t)$ satisfies second order ODE and it should take the form $T_n(t)=A_n \cos(...)+B_n\sin (...)$, where $A_n$ and $B_n$ are constants to be determined.  Now you should have obtained $U_n(x,t)=X_n(x)T_n(t)$;

(ii) Let $u(x,t)=\sum^\infty_{n=1}X_n(x)T_n(t)$ and then find $A_n$ and $B_n$ by fitting the initial condition.  \emph{Remark:  In the linear combination, the coefficient $C_n$ is embedded into $A_n$ and $B_n$.}

(iii)  Choose $D=L=1$.  Use the first 10 terms as your approximate.  Plot the graphs for $t=1, 1.5, 2, 2.5, 3$...and the initial data on the same coordinate.  What are your observations? Compare this with the heat equation.

(iv).  You can even try to plot the graphs for $t=-1$, $t=-2$, $t=-3$.  You may see that graphs propagate like a wave and this is why the PDE is called a wave equation.  What is the speed of wave propagation?
\begin{solution}
(i).  Since the corresponding EP has homogeneous DBC, according to the Sturm--Liouville theorem we can write $u(x,t)$ into the following eigen--expansions
\[u(x,t)=\sum_{n=1}^\infty C_n(t)\sin \frac{n\pi x}{L}.\]
Ok, I do not explain how and why $\sin$ any more!!! Substituting this series into the PDE gives rise to
\[C_n''(t)=-D\Big(\frac{n\pi}{L}\Big)^2C_n(t),\]
which is a second--order linear ODE and its solution takes the form
\begin{align*}
C_n(t)=A_n\cos{\frac{n\pi \sqrt{D} t}{L}}+B_n\sin{\frac{n\pi \sqrt{D} t}{L}}, n=1,2,...
\end{align*}
Note that $n=0$ is easily ignored thanks to the DBC above (however, it helps to always keep $n=0$ for your solution in practice and then decide if it is necessary, at least when you are a PDE rookie).   Now $u_n(x,t)=C_n(t) X_n(x)$ and the solution to (\ref{7}) takes the form
\begin{align*}
u(x,t)=\sum_{n=1}^{\infty} \Big(A_n\cos{\frac{n\pi \sqrt{D} t}{L}}+B_n\sin{\frac{n\pi \sqrt{D} t}{L}}\Big)\sin{\frac{n\pi x}{L}},
\end{align*}
where $A_n$ and $B_n$, $n\in\mathbb N^+$ are constants to be determined.   Note that the coefficients in the linear combination are embedded into $A_n$ and $B_n$.

(ii)  By matching the initial datum $u(x,0)=\phi(x)$, we have that
\begin{align*}
A_n=&\frac{2}{L}\int_{0}^{L} \phi(x)\sin{\frac{n\pi x}{L}}dx\\
=&\frac{2}{L}\int_{0}^{\frac{L}{2}}\frac{2h}{L}x\sin{\frac{n\pi x}{L}}dx+\frac{2}{L}\int^{L}_{\frac{L}{2}}\frac{2h}{L}(L-x)\sin{\frac{n\pi x}{L}}dx\\
=&\frac{8h}{n^2\pi^2}\sin{\frac{n\pi}{2}}\\
=&
\begin{cases}
\frac{8h(-1)^k}{(2k-1)^2\pi^2},&n=2k-1,k=1,2,...\\
0&n=2k,k=1,2,...;
\end{cases}
\end{align*}
by matching the initial datum $u_t(x,0)=0$, we can easily find that $B_n=0$.  Therefore we have that the solution is given by
\[u(x,t)=\sum_{k=1}^{\infty} \frac{8h(-1)^k}{(2k-1)^2\pi^2} \cos{\frac{(2k-1)\pi \sqrt{D} t}{L}}\sin{\frac{(2k-1)\pi x}{L}}.\]

(iii)-(iv).
When $D=L=h=1$ (should have assumed $h=1$), the approximate solution takes the form
\[u^N(x,t)=\sum_{k=1}^{N} \frac{8(-1)^k}{(2k-1)^2\pi^2}  \big(\cos (2k-1)\pi t\big)\big(\sin (2k-1)\pi x\big).\]

\begin{figure}[h!]%
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=0.85\textwidth]{hw2figure5.eps}\\
  \caption{Graphes of $u^{10}(x,t)$ at different times.  Note that all satisfy the DBC and there are certain periodicity in these solutions.}\label{figure4}
\end{figure}

\end{solution}


\item  This is another example that applies the method of separation of variables.  Consider the scenario that an agent starts with a total wealth $x$ at time $t$, and can invest the total wealth $X_s$ into a bond (risk-free) with a portion $\alpha_s$ and a stock (risky) with the rest portion $1-\alpha_s$.  Then idealized modeling of the evolution of the total wealth is the following differential equation
\[dX_s=X_s\big(r+(\mu-r)\alpha_s\big)dt+\sigma \alpha_sX_sdW_s,\]
where $r$ is the constant interest rate of the bond, and constants $\mu$ and $\sigma$ are the interest rate and volatility of the stock.  $W_s$ is the Brownian motion and it is a user-friendly choice that models the uncertainty or the ``risk" when investing in the stock.  Then an optimization problem arises when this agent opts to maximize the ``benefit" from the total wealth by altering the allocation $\alpha_s$.  That is, one aims in finding the maximum value function from the investment
\[u(x,t):=\sup_{\alpha_s\in\mathcal A}E[\mathbb U(X^{x,t}_T)].\]
Here $\mathbb U(\cdot)$ is the so-called utility function, and ${t,x}$ on the shoulder are included to highlight the effects endowment $x$ at time $t$.  Note that: i) $X_t$ is a stochastic process, hence the expectation is taken; ii) one may wonder why not to maximize $E[X^{x,t}_T]$ but $E[\mathbb U(X^{x,t}_T)]$.  This utility function describes the well-accepted belief that utility or ``satisfaction" should not be linear in wealth, but a concave function.  Imagine that eating two apples is less than twice satisfying as eating one.  Some may argue it might be more than twice in a certain situation which I agree with, however, this implies that a nonlinear function should be considered here anyhow, and that is the utility function.  You do not have to understand everything above to do this problem, but I explain to them here to give you a motivation why the optimal value function $u(x,t)$ above is of interest.

By the standard dynamic programming principle (or Bellman's optimality condition), one can show that this function solves the following
\begin{equation}\label{HJB}
\left\{
\begin{array}{ll}
u_t+rxu_x+\sup_{\alpha\in\mathbb R}\big[\alpha(\mu-r)xu_x+\frac{\alpha^2\sigma^2}{2}x^2u_{xx}\big]=0,&x\in (0,\infty),t\in(0,T),\\
u(x,T)=\mathbb U(x)=\frac{x^p}{p},&x\in (0,\infty),
\end{array}
\right.
\end{equation}
where for simplicity we assume that $\alpha$ is constant, and choose the so-called CRRV utility $\mathbb U(x)$ with $p\in(0,1)$.  Use the method of separation of variables to solve for the optimal $\alpha^*$ and the value function of (\ref{HJB}).  Suggest answer: $u(x,t)=e^{\lambda(T-t)}x^p/p$, where $\lambda=\frac{p(\mu-r)^2}{2(1-p)\sigma^2}+pr$, and the optimal control is $\alpha^*=\frac{\mu-r}{(1-p)\sigma^2}$.
\begin{solution}
Let us try $u(x,t)=X(x)T(t)$ which is assumed nonzero as usual, then the PDE in (\ref{HJB}) implies that
\[\frac{T'}{T}+rx\frac{X'}{X}+\sup_{\alpha\in\mathbb R}\Big[\alpha(\mu-r)x\frac{X'}{X}+\frac{\alpha^2\sigma^2x^2}{2}\frac{X''}{X}\Big]=0,\]
where prime $'$ denotes the derivative concerning the intrinsic variable.  Then one concludes that $\frac{T'}{T}=\lambda$ must be a constant and accordingly
\begin{equation}\label{euler}
rx\frac{X'}{X}+\sup_{\alpha\in\mathbb R}\Big[\alpha(\mu-r)x\frac{X'}{X}+\frac{\alpha^2\sigma^2x^2}{2}\frac{X''}{X}\Big]=-\lambda.
\end{equation}
We recognize that (\ref{euler}) has the pattern that differentiating $X$ once balances out $x$ in the coefficient and twice $x^2$ in the coefficient (when I was learning ODE, this was called an Euler's equation, and I do not know your story here).  Therefore we can easily guess that $X$ is a power function of $x$; on the other hand, the terminal condition is $u(x,T)=\frac{x^p}{p}$, then this power index must be $p$ hence $X(x)=Cx^p$ for some constant $C$ to be determined.

Bearing these facts in mind, let us proceed to find the optimal control $\alpha^*$.  To this, we find that $\alpha(\mu-r)x\frac{X'}{X}+\frac{\alpha^2\sigma^2x^2}{2}\frac{X''}{X}$, as a function of $\alpha$, is a parabola, and therefore one can easily find that its optimal value is attained at
\[\alpha^*=-\frac{(\mu-r)x\frac{X'}{X}}{\sigma^2x^2\frac{X''}{X}}=-\frac{(\mu-r)}{\sigma^2(p-1)}\]
as expected.  One can further find that $\lambda$ is the value given above.

I would like to comment that this explicit solution is available for this particular utility function, and in general, the PDE or HJB system can not be solved explicitly, at least NOT by the method of separation of variables.
\end{solution}



\item  Let us consider the following problem under RBC
\begin{equation}\label{NBVP1}
\left\{
\begin{array}{ll}
u_t=u_{xx},& x\in (0,1), t\in\mathbb R^+,\\
u(x,0)=x, &x\in(0,1), \\
u+u_x=0, & x=0,1, t\in\mathbb R^+.
\end{array}
\right.
\end{equation}

(i)  solve this problem in terms of infinite series;

(ii) use computer program to plot the sum of first $N$--terms $u^N(x,t)$
\[u^N(x,t):=\sum C_nX_n(x)T_n(t)\]
of the series at time $t=0.1$ by taking $N=1, 2, 3, 10$ (in different colors or lines such as dash, dot, etc) respectively.  Then again we shall observe that $u^N(x,t)$ converges as $N$ increases and $u^N(x,t)$ to approximate the true solution if $N$ is large enough;

(iii) assume that $u^{10}(x,t)$ is a good enough approximation of the exact solution (i.e., the infinite series)--this applies in the
sequel.  Plot the graphs of $u^{10}(x,t)$ for $t=0.01,0.05,01,1,2,5,...$.   What are your observation of $u(x,t)$ when $t$ is large?
\begin{solution}
First of all, we recognize the corresponding eigen-value problem the eigen-functions of which form an orthogonal basis of $L^2$ is
\[
\left\{
\begin{array}{ll}
X''+\lambda X=0,& x\in (0,1),\\
X+X'=0, & x=0,1.
\end{array}
\right.
\]
You should be able to verify that, which I skip here, $\lambda=\mu^2$ for some $\mu$.  Indeed, one finds that the eigen-pairs are
\[(X_k,\lambda_k)=\Big\{\Big(\sin \frac{k\pi x}{L}-\frac{k\pi}{L}\cos \frac{k\pi x}{L},(\frac{k\pi}{L})^2\Big\}_{k=1}^\infty,\]
where as $X_0\equiv 0$.  Then one invokes Sturm--Liouville Theorem and write the solution in terms of infinite series as
\[u(x,t)=\sum_{k=1}^\infty C_ke^{-(k\pi/L)^2t}X_k(x).\]

\begin{figure}[h!]%[h]
  \centering
\includegraphics[width=0.485\textwidth]{hw3figure31.eps}\hspace{-8mm}
\includegraphics[width=0.485\textwidth]{hw3figure32.eps}
\caption{\textbf{Left Column}: the first $N$-th sum at time $t=0.1$ for $N=1,2,3$ and 10.  \textbf{Right Column}: the error in $L^\infty$ for each $N$ large.  Similar as above, we observe that when $N>10$ the finite sum is an approximation with error tolerance of $O(10^{-55})$.}
\end{figure}

\begin{figure}[h!]%[h]
  \centering
\includegraphics[width=0.85\textwidth]{hw3figure33.eps}
\caption{Evolution of approximated solutions, which develop a boundary layer at $x=1$ for a short time and eventually converges to zero everywhere.  This agrees well with our intuitive understanding of the large time behavior.}
\end{figure}

Now we are left to determine the coefficients $C_k$, $k\in\mathbb N^+$.  To this end, we evaluate the series at $t=0$ and find that
\[u(x,0)=x=\sum_{k=1}^\infty C_k X_k(x).\]
Note we know from the proof that $X_k(x)$ are orthogonal to each other in $L^2$, therefore we test both hand side of the equation above by $X_k$ and collect
\begin{align*}
C_k=&\frac{\int_0^1 xX_k(x)dx}{\int_0^1 X^2_k(x)dx}\\
   =&\frac{2}{(k\pi)^2+1}\Bigg(\frac{\sin k\pi x-k\pi x\cos k\pi x}{(k\pi)^2}\Bigg|_0^1-\frac{k\pi x\sin k\pi x+\cos k\pi x}{k\pi}\Bigg|_0^1\Bigg) \\
   =&\frac{2}{(k\pi)^2+1}\Big(\frac{-k\pi \cos k\pi}{(k\pi)^2}-\frac{\cos k\pi-1}{k\pi}\Big)\\
   =& \frac{2}{(k\pi)^2+1}\frac{1+2(-1)^k}{k\pi}  , k\in\mathbb N^+.
\end{align*}

\end{solution}



\item  Let us consider the following problem with heating/cooling resources under DBC
\begin{equation}\label{DBVP1}
\left\{
\begin{array}{ll}
u_t=u_{xx}+e^{-t}\sin 2x,& x\in (0,1), t\in\mathbb R^+,\\
u(x,0)=x, &x\in(0,1), \\
u=0, & x=0,1, t\in\mathbb R^+.
\end{array}
\right.
\end{equation}
Do all the work as in Problem 2.
\begin{solution}
After recognizing the boundary condition as a DBC, we know from the Sturm--Liouville Theorem that the solution can be uniquely written as the following series
\[u(x,t)=\sum_{n=1}^\infty C_n(t)\sin n\pi x.\]
Then the PDE implies that
\[\sum_{n=1}^\infty C'_n(t)\sin n\pi x=-\sum_{n=1}^\infty(n\pi)^2C_n(t)\sin n\pi x+e^{-t}\sin 2x,\]
hence we have that
\begin{equation}\label{ODE1}
C'_2(t)=-(2\pi)^2C_2(t)+e^{-t}
\end{equation}
and
\begin{equation}\label{ODE2}
C'_n(t)=-(n\pi)^2C_n(t), \forall n\neq 2.
\end{equation}
Equation (\ref{ODE2}) is very simple and one immediately collects that
\[C_n(t)=C_n(0)e^{-(n\pi)^2t}, \forall n\neq 2.\]
Equation (\ref{ODE1}) can be a little tricky if you do not take advantage of certain techniques called integrating factor.
\begin{figure}[h!]%
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=1\textwidth]{hw4dbc.png}\\
  \caption{Illustration of convergence to zero of the solution to Problem (\ref{DBVP1}).  \textbf{Left:} we plot the solution several times to illustrate the stabilization of the solution.  One can see that the dynamics are dominated by diffusion as well the boundary condition.  \textbf{Right}:  We plot the solution at even larger times to illustrate the dominance of the dynamics by the kinetics or $\sin 2\pi x$.  One can easily recognize that now the diffusion is more or less smeared out and PDE is dominated by the ODE (in the sense that the solution follows the mode of the latter).}\label{ }
\end{figure}

Indeed, one does not need to know this technique to the end, and let me show you how.  Let us denote for notational simplicity that $\lambda:=4\pi^2$.   Then we agree that (\ref{ODE1}) can be rewritten as $(e^{\lambda t}C_2(t))'e^{-\lambda t}=e^{t}$, or equivalently
\[\big(e^{\lambda t}C_2(t)\big)'=e^{(\lambda -1)t}.\]
Integrating this identity over $(0,t)$ gives us
\[C_2(t)=C_2(0)e^{-\lambda t}+\frac{1}{\lambda -1}\Big(e^{-t}-e^{-\lambda t}\Big)=C_2(0)e^{-4\pi^2 t}+\frac{1}{4\pi^2 -1}\Big(e^{-t}-e^{-4\pi^2 t}\Big).\]
Then the solution can be rewritten into the following series
\[u(x,t)=C_2(t)\sin 2\pi x+\sum_{n\neq2}C_n(t)\sin n\pi x,\]
where $C_n(0)$, $n\geq1$, are determined by the initial condition as
\[C_n(0)=2\int_0^1 x\sin n\pi xdx=\frac{2}{n\pi}(-1)^{n-1}, \forall n\geq1.\]
\end{solution}


\item  Let us consider the following problem with heating/cooling resources under NBC
\begin{equation}\label{NBVP1}
\left\{
\begin{array}{ll}
u_t=u_{xx}+e^{-t}\sin 2x,& x\in (0,1), t\in\mathbb R^+,\\
u(x,0)=x, &x\in(0,1), \\
u_x=0, & x=0,1, t\in\mathbb R^+.
\end{array}
\right.
\end{equation}

Do all the work as in Problem 2.  Summarize/propose all your observations/guesses from Problems 2-4 on the effects of IC, BC, and PDE on the long-time behaviors.
\begin{solution}
The approach is pretty much the same except that now the series become
\[u(x,t)=\sum_{n=0}^\infty C_n(t)\cos n\pi x,\]
in light of the NBC, whence the PDE implies that
\[\sum_{n=0}^\infty C'_n(t)\cos n\pi x=-\sum_{n=0}^\infty(n\pi)^2C_n(t)\cos n\pi x+e^{-t}\sin 2x.\]
Testing this ODE by $\cos n\pi x$ over $(0,1)$, we find that
\[C'_n(t)=-(n\pi)^2C_n(t)+2e^{-t}\int_0^1\sin 2x \cos n\pi xdx, \forall n\geq0.\]
To evaluate the integral, one can use the triangle formula $\sin a \cos b=\frac{\sin(a+b)-\sin(a-b)}{2}$.  My calculations tell that this integral is
\[\int_0^1\sin 2x \cos n\pi xdx=\frac{1-\cos (2+n\pi)}{2(2+n\pi)}+\frac{\cos(2-n\pi)-1}{2(2-n\pi)},n\geq0.\]
This ODE can be solved the same as (\ref{ODE1}), and the coefficients $C_n(0)$ are then explicitly determined by the initial condition as usual.  I skip the rest calculations and plots.  Anyhow, by now you should be able to evaluate everything and collect the desired series for this solution.
\end{solution}

\item Solve the following IBVP and write it solution in terms of infinite series
\begin{equation}
\left\{
\begin{array}{ll}
u_t=Du_{xx},& x\in(-L,L),t\in\mathbb R^+\\
u(x,0)=\phi(x),&x\in(-L,L),\\
u(-L,t)=u(L,t)=0, &t\in\mathbb R^+.
\end{array}
\right.
\end{equation}
\emph{Remark:  You are encouraged to explore this problem over $(a,b)$ for general $a,b$ yourself, though I do not require you to do so or turn it in for this course.}
\begin{solution}
First of all, we have that the eigen--value problem associated with this system is
\begin{equation*}
\left\{
\begin{array}{ll}
X''+\lambda X=0,& x\in(-L,L),\\
X(-L)=X(L)=0. &
\end{array}
\right.
\end{equation*}
Now we need to find the eigen--pairs to the problem above.  While you can do it by straightforward calculations, an alternative way is to do as follows:
let \[Y(x)=X(x-L)\]
and then it is easy to see that the eigen--value problem now becomes
\begin{equation*}
\left\{
\begin{array}{ll}
Y''+\lambda Y=0,& x\in(0,2L),\\
Y(0)=Y(2L)=0. &
\end{array}
\right.
\end{equation*}
It is well known that the eigen--pairs are
\[Y_n(x)=\sin \frac{n\pi x}{2L},\lambda_n=\Big(\frac{n\pi}{2L}\Big)^2,n=1,2,...\]
therefore we have that
\[X_n(x)=Y_n(x+L)=\sin \frac{n\pi (x+L)}{2L}=\sin \Big(\frac{n\pi x}{2L}+\frac{n\pi}{2}\Big),\lambda_n=\Big(\frac{n\pi}{2L}\Big)^2,n=1,2,...\]
moreover, we can also find that
\[\int_{-L}^L X^2_n(x)dx=\int_0^{2L}Y^2_n(x)dx=\int_0^{2L}\sin^2 \frac{n\pi x}{2L}dx=L,\]
while \[\int_{-L}^L X_m(x)X_n(x)dx=0,m\neq n.\]

According to the Sturm--Liouville Theory, we can write the solution in terms of the infinite series
\[u(x,t)=\sum_{n=1}^\infty C_n(t) \sin \frac{n\pi (x+L)}{2L}.\]
Substituting this solution into the PDE gives us
\[\sum_{n=1}^\infty C_n'(t) \sin \frac{n\pi (x+L)}{2L}=-D\sum_{n=1}^\infty C_n(t) \Big(\frac{n\pi}{2L}\Big)^2\sin \frac{n\pi (x+L)}{2L};\]
%on the other hand, we can have from straightforward calculations that
%\[\int_{-L}^L \sin^2 \frac{n\pi x}{L}dx=\frac{x}{2}-\frac{L\sin \frac{2n\pi x}{L}}{4n\pi}\Big|_{-L}^L=L,\]
%while \[\int_{-L}^L \sin \frac{m\pi (x-L)}{L} \sin \frac{n\pi (x-L)}{L}dx=0,m\neq n.\]
Multiply BHS of the above system by $X_n(x)$ and then integrating it over $(-L,L)$, we obtain that
\[C_n'(t)=- D \Big(\frac{n\pi}{2L}\Big)^2C_n(t);\]
solving this ODE gives us
\[C_n(t)=C_n(0)e^{-D(\frac{n\pi}{2L})^2t},\]
where $C_n(0)$ can be evaluated by the initial condition as
\[C_n(0)=\frac{1}{L}\int_{-L}^L \phi(x) \sin \frac{n\pi (x+L)}{2L}dx.\]
\end{solution}


\item  Separation of variables can also be applied to tackle some (most likely linear) PDEs in higher dimensions.  Consider
\begin{equation}
\left\{
\begin{array}{ll}
u_t=D\Delta u,& x\in\Omega,t\in\mathbb R^+,\\
u(x,0)=\phi(x),&x\in\Omega,\\
u(x,t)=0, &x\in\partial \Omega, t\in\mathbb R^+.
\end{array}
\right.
\end{equation}
Write down $u(x,t)$ in terms of an infinite series by mimicking the approaches for 1D IBVP.  You can assume similar properties of the eigen-value problem that you encounter.
\begin{solution}
We write $u(x,t)$ into
\[u(x,t)=\sum_{n=1}^\infty C_n(t)w_n(x),\]
where $w_n$ is an eigen--function to the following problem
\begin{equation}\label{MDEP}
\left\{
\begin{array}{ll}
\Delta w+\lambda w=0,& x\in\Omega\\
w=0, &x\in\partial \Omega.
\end{array}
\right.
\end{equation}
Similarly as Sturm--Liouville theory, one has that $\{w_n\}_{n=1}^\infty$ form an orthogonal basis of $L^2(\Omega)$.  Then encoding the initial data gives us that
\[C_n(t)=C_n(0)e^{-D\lambda_n t},\]
$\lambda_n$ the eigen--value and
\[C_n(0)=\frac{\int_\Omega \phi(x)w_n(x)dx}{\int_\Omega w^2_n(x)dx},\]
therefore we have that
\[u(x,t)=\sum_{n=0}^\infty C_n(t)w_n(x).\]  I would like to mention that in general $w_0\equiv 0$, however a rigorous verification requires some advanced theories/studies about the eigen--value problem.
\end{solution}

\item It seems in the problem above, more needed to be said about the following multi--dimensional eigen--value problem with $w\in C^2(\Omega)\cap C(\bar\Omega)$ (i.e., twice differentiable in the interior and continuous up to the boundary)
\begin{equation}\label{DEP}
\left\{
\begin{array}{ll}
\Delta w(x)+\lambda w(x)=0,& x\in\Omega,\\
w(x)=0, &x\in\partial \Omega.
\end{array}
\right.
\end{equation}
Again, $<w,\lambda>$ is called eigen-pair and $w\not\equiv0$ is needed (see our discussions above).  Prove that $\lambda>0$.  Hint: multiply BHS by $w$ and then integrate it over $\Omega$ by parts and you will see that $\lambda\geq0$; moreover $w\equiv 0$ if $\lambda=0$ (continuity up to the boundary).  \emph{Remark: Similar as in 1D, there are infinitely many eigen--pairs.  The smallest eigen--value, denoted by $\lambda_1$, is called the principal eigen--value.  For example, the principal eigen--value in 1D is $(\frac{\pi}{L})^2$.  The effect of $\lambda_1$ is that it determines how fast the solutions converge/stabilize.}
\begin{solution}
Testing the EP by $w$ and then integrating it over $\Omega$ by parts, we have
\[\lambda=\frac{\int_\Omega |\nabla w|^2}{\int_\Omega w^2},\]
with $dx$ skipped in both integrals.  It is easy to see that $\lambda \geq0$.  If $\lambda=0$, we must have that $w\equiv$ a constant, hence $w\equiv 0$ in light of the boundary condition, however, this is ruled out since $w$ is an eigen--function.  Therefore we must have that $\lambda>0$.
\end{solution}

\item Consider the following problem
\begin{equation}\label{ndep}
\left\{
\begin{array}{ll}
\Delta w+\lambda w=0,& x\in \Omega,\\
\alpha\frac{\partial u}{\partial \textbf{n}}+\beta u=0, &x\in\partial\Omega,
\end{array}
\right.
\end{equation}
where $\Omega$ is a bounded domain in $\mathbb R^n$, $n\geq2$, and $\alpha^2+\beta^2\neq0$.  Prove that $w_m$ and $w_n$, corresponding to $\lambda_m$ and $\lambda_n$ respectively, are orthogonal in $L^2(\Omega)$, whenever $\lambda_m\neq \lambda_n$.
\begin{solution}
The proof is the same as that for its one-dimensional counterpart, except that one applies the divergence theorem (or Green's identities) here.  I skip typing the details.
\end{solution}


\item The multi-dimensional eigen-value problem over special geometries can be solved explicitly.  For example, choose $\Omega=(0,a)\times(0,b)$ and consider the Dirichlet eigen-value problem (\ref{DEP}).  Find its eigen-pairs by starting with $u(x,y)=X(x)Y(y)$.  Hint: your solution should be of the form $u_{mn}(x,y)=X_m(x)Y_n(y)$ and $\lambda_{mn}$, $m,n\in\mathbb N$.
\begin{solution}
We write the solution to (\ref{DEP}) as $w(x,y)=X(x)Y (y)$ and substitute it into the PDE to collect
that
\[X''Y+XY''+\lambda XY=0,\]
since $XY \neq 0$, we have that
\[\frac{X''}{X}+\frac{Y''}{Y}+\lambda=0,\]
hence both $\frac{X''}{X}$ and $\frac{Y''}{Y}$ must be constants, which we shall denote by $\alpha$ and $\beta$ respectively.  Now I assume that you are able to show that $X(x)$ should take the
$X_m=\sin \frac{m\pi x}{a}$  and $Y_n=\sin \frac{n\pi y}{b}$.  The key point is that $X$ and $Y$ are independent hence each admits its sub-index.   Finally, you should be able to find that $u_{mn}=\sin \frac{m\pi x}{a}\sin \frac{n\pi y}{b}$, $m,n\in\mathbb N^+$; moreover, the eigen-values are $\lambda_{mn}=(m\pi/a)^2+(n\pi/b)^2$, $m,n\in\mathbb N^+$.
\end{solution}

\item One can also employ the method of separation of variables to solve other types of (multi--dimensional) PDEs.  For example, consider the following problem over a 2D square $\Omega=(0,1)\times(0,1)$
\begin{equation}
\left\{
\begin{array}{ll}
\Delta u=0,& x\in(0,1)\times(0,1)\\
u_x(0,y)=u_x(1,y)=0,&y\in(0,1),\\
u(x,0)=0, u(x,1)=x. &
\end{array}
\right.
\end{equation}
Find $u(x,y)$ in terms of infinite series by starting with $u(x,y)=X(x)Y(y)$.  Suggested answer:
\[u(x,y)=\frac{y}{2}+\sum_{n=1}^\infty \frac{2((-1)^n-1)}{(n\pi)^2}\frac{e^{n\pi y}-e^{-n\pi y}}{e^{n\pi}-e^{-n\pi}}\cos n\pi x.\]
Plot $u(x,y)$ by choosing $N$ large to see the graph yourself if it matches the boundary conditions.  \emph{Remark: If $\Delta u=0$, we say that $u$ is a harmonic function.  More about harmonic functions will be discussed with details in coming lectures.}
\begin{solution}
Using the trial solution of the form \[u(x,y)=X(x)Y(y)\]
and invoking the PDE, we have that for some constant $\lambda$
\[\frac{X''}{X}=-\frac{Y''}{Y}=-\lambda;\]
$X$ satisfying the Neumann boundary condition gives us
\[X_n(x)=\cos n \pi x, \lambda_n=(n\pi)^2,n=0,1,2,...\]
On the other hand, $Y(y)$ satisfies the ODE
\[Y''=(n\pi)^2Y\]
hence $Y_n(y)$ takes the form $Y_n(y)=a_ne^{n\pi y}+b_ne^{-n\pi y}$ for $n=1,2,...$ and $Y_0(y)=a_0y+b_0$ for $n=0$; moreover, encoding the boundary condition gives us $Y(0)=0$ hence
\[Y_0(y)=a_0y, Y_n(y)=a_n(e^{n\pi y}-e^{-n\pi y}), n=1,2,...\]
therefore we have
\[u(x,y)=\sum_{n=0}^\infty u_n(x,y)=a_0y+\sum_{n=1}^\infty a_n(e^{n\pi y}-e^{-n\pi y})\cos n\pi x,\]
which satisfies the whole problem except the boundary condition at the top of the square.  To this end, we equate
\[u(x,1)=\sum_{n=0}^\infty u_n(x,1)=a_0+\sum_{n=1}^\infty a_n(e^{n\pi }-e^{-n\pi })\cos n\pi x=x\]
from which we obtain
\[a_0=\int_0^2 xdx=\frac{1}{2}\]
and
\[a_n(e^{n\pi }-e^{-n\pi })=2\int_0^1 x\cos nx dx=\frac{2}{(n\pi)^2}(\cos n \pi-1),n=1,2,...\]
finally, we collect
\[u(x,y)=\frac{y}{2}+\sum_{n=1}^\infty \frac{2((-1)^n-1)}{(n\pi)^2}\frac{e^{n\pi y}-e^{-n\pi y}}{e^{n\pi}-e^{-n\pi}}\cos n\pi x\]
as suggested.
\begin{figure}[h!]%
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{hw2figure6.eps}
        \caption{Plots of the approximation $u^{10}(x,y)$.}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{hw2figure7.eps}
        \caption{Absolute error for different $N$.  It provides evidence that $N=10$ is already a good approximation if an upper bound of error $\varepsilon\leq 0.01$ is acceptable.}
    \end{subfigure}
\label{figure5}
\end{figure}
\end{solution}


\item  We observe in class that the method of separation of variables can be applied to solve non-autonomous problems (i.e., the reaction term $f$ does not depend on $u$), whereas the PDE $u_t=u_{xx}+f(u)$ is nonlinear and can not be solved explicitly in general.  However, this method is applicable as long as the corresponding ODE is solvable.  To see this, let us consider the following non-autonomous problem
\begin{equation}\label{5}
\left\{
\begin{array}{ll}
u_t=u_{xx}-\lambda u+\mu,& x\in(0,L),t\in\mathbb R^+,\\
u(x,0)=0,&x\in(0,L),\\
u_x(0,t)=0, u_x(L,t)=0, &t\in\mathbb R^+,
\end{array}
\right.
\end{equation}
where $\lambda$ and $\mu$ are positive constants.

i) solve it explicitly;

ii) what is the limit of $u(x,t)$ as $t\rightarrow \infty$?

iii) what is the solution to the following ODE
\begin{equation}
\left\{
\begin{array}{ll}
u_t=-\lambda u+\mu,&t\in\mathbb R^+,\\
u(0)=0.&
\end{array}
\right.
\end{equation}
What is(are) your observation(s) after comparing the solutions of the PDE and the ODE; use intuition to justify it(them)?
\begin{solution}
I assume that you are able to work this problem out by introducing $w$ as suggested.  Here in the following, I shall show that this is not necessary.

The IBVP has an homogeneous NBC, therefore we can substitute its eigen--expansion
\[u(x,t)=\sum_{n=0}^\infty C_n(t)\cos \frac{n\pi x}{L}\]
into the PDE and collect that
\[\sum_{n=0}^\infty C'_n(t)\cos \frac{n\pi x}{L}=-\sum_{n=0}^\infty \Big(\frac{n\pi}{L}\Big)^2C_n(t)\cos \frac{n\pi x}{L}-\lambda \sum_{n=0}^\infty C_n(t)\cos \frac{n\pi x}{L}+\mu.\]
Equating the coefficients gives us
\[C_n'(t)=-\Big(\big(\frac{n\pi}{L}\big)^2+\lambda\Big)C_n(t)+\frac{2\mu}{L}\int_0^L \cos \frac{n\pi x}{L},\]
i.e.,
\[C_n'(t)=-\Big(\big(\frac{n\pi}{L}\big)^2+\lambda\Big)C_n(t).\]
Solving this ODE with the initial condition, we have
\[C_0(t)=\frac{\mu}{\lambda}\big(1-e^{-\lambda t}\big), C_n(t)=0,n=1,2,....\]
Therefore we have that
\[u(x,t)=C_0(t)=\frac{\mu}{\lambda}\big(1-e^{-\lambda t}\big).\]
It is quick to see that $u(x,t)\rightarrow \frac{\mu}{\lambda}$ as $t\rightarrow\infty$.

Indeed, we can formally expect this solution without even solving the PDE.  This IBVP describes a homogeneous well-insulated bar with zero temperature, therefore, there is no heat flux at all afterward, hence the PDE indeed should be an ODE.  Solving the ODE gives the desired solution.
\end{solution}

\item  Solve the following non-autonomous problem with a different initial condition
\begin{equation}\label{5a}
\left\{
\begin{array}{ll}
u_t=u_{xx}-\lambda u+\mu,& x\in(0,L),t\in\mathbb R^+,\\
u(x,0)=\phi(x),&x\in(0,L),\\
u_x(0,t)=0, u_x(L,t)=0, &t\in\mathbb R^+,
\end{array}
\right.
\end{equation}
where $\lambda$ and $\mu$ are positive constants.  Find the (pointwise) limit of $u(x,t)$ as $t\rightarrow\infty$?  If you can not, do some numerical simulations by choosing $N=10$ and choosing $\phi(x)=x$ or $1+\cos \frac{\pi x}{L}$ to give you some intuitions.
\begin{solution}
We have that, all the calculations leading to
\[u(x,t)=\sum_{n=0}^\infty C_n(t)\cos \frac{n\pi x}{L}\]
hold with
\[C_n(t)=C_n(0)e^{-((\frac{n\pi}{L})^2+\lambda)t}, n=1,2,...\]
and $C_0(t)$ satisfies the ODE, except that we have to find $C_n$ to cope with the general initial data $\phi(x)$.  This easily implies that
\[C_n(0)=\frac{2}{L}\int_0^ L \phi(x)\cos \frac{n\pi x}{L}dx. \]
Finally, one has that
\[u(x,t)=C_0(t)+\sum_{n=1}^\infty C_n(0)e^{-((\frac{n\pi}{L})^2+\lambda)t}\cos \frac{n\pi x}{L}\]
or precisely
\[u(x,t)=C_0(t)+\frac{2}{L} \sum_{n=1}^\infty \Big(\int_0^ L \phi(x)\cos \frac{n\pi \xi}{L} \cos \frac{n\pi x}{L} d\xi \Big)e^{-((\frac{n\pi}{L})^2+\lambda)t},\]
then one can easily show that the series converges and goes to zero exponentially, hence $u(x,t)$ behaves like $C_0(t)$ for $t$ large.  Solve this ODE of $C_0(t)$ gives the desired conclusion that $u(x,t)\rightarrow \frac{\mu}{\lambda}$, the same as above.

I skip the plots when $\phi\not\equiv 0$ here, but you should do some numerical experiments to show that $u\rightarrow \frac{\mu}{\lambda}$ as expected.
\end{solution}
\end{enumerate}


\end{document}
\endinput
